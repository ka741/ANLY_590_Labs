{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Lab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOkBF0K6P6MC"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tfk\n",
        "import tensorflow.keras.layers as tfkl\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdCU982WwzFo"
      },
      "source": [
        "In this example, we're going to train a [CharRNN](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) on a body of Shakespearian text. Ultimtely, this is an unsuperived learning task. But similar to our previous explorations in unsupervised DL, we will use an unlabeled dataset and create many samples of labeled data that we can use with our familiar supervised loss functions. The result will be a model that has learned the statistical properties of the input text, and can then be considered a \"generative\" model of language because we can use it to generate synthetic passages of Shakespeare.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX7qrncTRKN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c6838b-2aa2-4978-d9ec-3e036fb69965"
      },
      "source": [
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iek9QSARq1L"
      },
      "source": [
        "file_path = \"/content/gdrive/My Drive/dNN/shakespeare.txt\"\n",
        "\n",
        "with open(file_path,\"r\") as f:\n",
        "  text = f.read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie2LtLF4Vv6A"
      },
      "source": [
        "We've loaded our Shakespeare text, let's take a look at a random snippet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVFmTUsGWePe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4810bb23-d7a7-42b8-9f1c-b53c9ed4d467"
      },
      "source": [
        "print(text[31600:32000])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " lies i' the second chamber?\n",
            "  LADY MACBETH. Donalbain.\n",
            "  MACBETH. This is a sorry sight.           [Looks on his hands.\n",
            "  LADY MACBETH. A foolish thought, to say a sorry sight.\n",
            "  MACBETH. There's one did laugh in 's sleep, and one cried,\n",
            "      \"Murther!\"\n",
            "    That they did wake each other. I stood and heard them,\n",
            "    But they did say their prayers and address'd them\n",
            "    Again to sleep.\n",
            "  LADY MACB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLXQHFUsW0xu"
      },
      "source": [
        "We need to convert our text into numeric arrays, the next several blocks accomplish this.\n",
        "\n",
        "First, we'll create a mapping between characters and their numeric index. We'll also create the reverse mapping, which is useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkvcQEUASXQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf233e4-5f94-4aaa-dcf2-ca778d73598c"
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "## total chars = 75 meaning a one hot encoding vecotr len 75"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XexyPZdAXC0p"
      },
      "source": [
        "Next, we'll create a training set of sub-sequences. Remember, we're trying to train a model to be able to predict the next chracter if it is given several characters of a subsequence. So we will create training pairs where each X is a fixed-length subsequences and each Y is the corresponding next letter in the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej4RdC76S7RB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c959b94-5397-478a-fb4e-d4b90fc12af2"
      },
      "source": [
        "maxlen = 40 # make the taining data 40 letters # target will be 41st letter\n",
        "step = 3 # skip every 3 letter\n",
        "sub_sequences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sub_sequences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen]) # grab the 41st letter\n",
        "print('nb sequences:', len(sub_sequences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 38700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVHru3qPWX8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b95a0e-fca8-4a2a-9623-4a47b8ba2db3"
      },
      "source": [
        "k=300\n",
        "print(\"(Sequence):\\n\" + sub_sequences[k])\n",
        "print(\"\\n(Target Character): \\n\" + next_chars[k])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Sequence):\n",
            " and other Apparitions\n",
            "  Lords, Gentleme\n",
            "\n",
            "(Target Character): \n",
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD2QxlOAW8zQ"
      },
      "source": [
        "Next we'll create one-hot vectors for our sub-sequences. The tensor we create here will be shaped as (num_sequences x sequence_length x alphabet_size)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfQRBmiNWehk"
      },
      "source": [
        "# 3-d - sequences, size each seq, size of onehot (len of chars list i.e. total number of chars in vocabulary)\n",
        "X = np.zeros((len(sub_sequences), maxlen, len(chars)), dtype=np.uint8)\n",
        "# 38,000x75 - onehot vector for each predicition\n",
        "Y = np.zeros((len(sub_sequences), len(chars)), dtype=np.uint8)\n",
        "for i, seq in enumerate(sub_sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "        Y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4qxjsGDXLtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a0734f-4fcf-41ae-8fca-05959c24aaa7"
      },
      "source": [
        "X[0,0,:]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "423pgyKqXnE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3f4b6e-b81e-4501-9d66-21cabf0aa349"
      },
      "source": [
        "Y[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dJrr1caYVnI"
      },
      "source": [
        "Our RNN model will be quite simple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95NSRVMpYGAT"
      },
      "source": [
        "char_rnn = Sequential()\n",
        "# 128 cells in LSTM\n",
        "# each x is len 40x tot vocal size (75) - dont need to tell it the seq len but its faster if you do\n",
        "char_rnn.add(tfkl.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "# make a prediction using softamx over all 75 letters\n",
        "char_rnn.add(tfkl.Dense(len(chars),activation=\"softmax\"))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4xdUMP_Y6iu"
      },
      "source": [
        "char_rnn.compile(loss='categorical_crossentropy', optimizer=tfk.optimizers.RMSprop(lr=0.01))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGDTEd0GZFNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b5d79f-80dc-4670-f29e-09b0472c8c6a"
      },
      "source": [
        "# train, can keep clicking train and it will imporove the model i.e. keep running cell - get smaller loss function\n",
        "char_rnn.fit(X,Y, epochs=20, batch_size=1024)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.5647\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.5560\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5418\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.5345\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.5245\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5166\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.5139\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.5021\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.4966\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.4844\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4775\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.4795\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4710\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4519\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4600\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4524\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.4452\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4447\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4369\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.4401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f535f79e7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hhAWPgRX96V"
      },
      "source": [
        "Once we have a trained model, we can simulate new text by making predictions about the next character and then drawing characters in proportion to the predicted probabilities. And then simple repeat that process over and over, each time drawing the next character."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKxkchaA4ckb"
      },
      "source": [
        "What to do with the output probabilities?\n",
        "Use a train model to generate new sequences\n",
        "  - see which prediction is the highest\n",
        "  - append that to the seed sequence and move the seed sequence over and\n",
        "  feed it back to the network, based on that predicition it will predict a new letter\n",
        "-OR-\n",
        "Take the softmax as a probability vector and draw a random character by it's index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMpJwYSsZSoc"
      },
      "source": [
        "def draw_char(probs):\n",
        "    probs = np.asarray(probs).astype('float64')\n",
        "    if sum(probs) != 1.0:\n",
        "      probs = probs / np.sum(probs)\n",
        "    draw = np.random.choice(range(len(probs)) , p=probs)\n",
        "    return draw\n",
        "\n",
        "def sample_text(model, sample_length=100):\n",
        "    start = np.random.randint(0, len(text) - maxlen - 1)\n",
        "    sequence = text[start: start + maxlen]\n",
        "  \n",
        "    x_preds = np.zeros((sample_length, maxlen, len(chars)))\n",
        "    for i in range(sample_length):\n",
        "        for t, char in enumerate(sequence[-maxlen:]):\n",
        "            x_preds[i, t, char_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(np.expand_dims(x_preds[i,:,:], axis=0), verbose=0)[0]\n",
        "        next_index = draw_char(preds)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        sequence += next_char\n",
        "    return sequence"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHD5iDlHayL7"
      },
      "source": [
        "sim = sample_text(char_rnn,sample_length=500) "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOP0ljRtOEmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1034d8be-6c72-4fe5-b3b4-a5c6bea5816e"
      },
      "source": [
        "# do the first option and generate new sequences of characters\n",
        "print(sim)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "e,\n",
            "    They are not yet come back. But I hade they.\n",
            "    Thou loses again fround as his swains, \n",
            "    You smild for rade folors hath of vales\n",
            "    Then for at hade of sliet flame fried?\n",
            "                                              Munching?\n",
            "\n",
            "                      Enter Macbeth.\n",
            "\n",
            "  MACBETH. To keips us all man cortle; the lidelan,\n",
            "    Hath not somelt.\n",
            "  MACBETH. [Which it same bordfed speetle your himse,\n",
            "    Ne moment grainsing theming thos frees us.\n",
            "    Most saying.\n",
            "\n",
            "    Leven placither it noble ture as hasthers wereabes\n",
            "    The slamoma\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj4kXg4BTbOc"
      },
      "source": [
        "Notice that we can do pretty well to learn the typical statistical patterns of this text and then simulate new text that appears to be very similar to legitimate Shakespeare. \n",
        "\n",
        "But just a caution - we can also do pretty well with a much simpler method (Markov model): http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139\n",
        "\n",
        "So the lesson is to try something simple before jumping right in to deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5IE5xprp3RS"
      },
      "source": [
        "## Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoN_s6nQsDdn"
      },
      "source": [
        "In this example, we're going to use an RNN for sequence classification. The task we'll set up is to generate a training set of randomized strings, and train our model to detect whether a string contains any vowels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isy5RPDdsTYT"
      },
      "source": [
        "First, we'll create a training dataset of short randomized character sequences and the corresponding label of whether or not they contain at least one vowel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE6C-Xl6p5W7"
      },
      "source": [
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI7QA2Ewp-ZJ"
      },
      "source": [
        "def contains_vowels(sequence):\n",
        "  vowels = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n",
        "  return any([vowel in list(sequence) for vowel in vowels])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ9cEhMrqtoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02020c8e-0cde-4615-ccbf-04d7613200a0"
      },
      "source": [
        "contains_vowels(\"gradient\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwBEUPYwp9Z0"
      },
      "source": [
        "sequences = []\n",
        "labels = []\n",
        "for i in range(10000):\n",
        " char_list = np.random.choice( list(string.ascii_lowercase), size = 5, replace=True)\n",
        " seq = \"\".join(char_list)\n",
        " sequences.append(seq)\n",
        " labels.append(int(contains_vowels(seq)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkJXdy5krgHn"
      },
      "source": [
        "df = pd.DataFrame({\"sequence\": sequences, \"label\":labels})"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubAQf53Dr8zy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "de561940-afd0-4ccc-b16e-3fc774e1cc94"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>edued</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>deyyw</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zdjho</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>esrlt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gzovf</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sequence  label\n",
              "0    edued      1\n",
              "1    deyyw      1\n",
              "2    zdjho      1\n",
              "3    esrlt      1\n",
              "4    gzovf      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xkX8Xa8sfID"
      },
      "source": [
        "Next, set up and train an RNN (of any type) to solve this task. What preprocessing will you need to do first on the raw data in order to prepare it for the network?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1FjTzVCTUbj",
        "outputId": "bae60886-af7b-4da5-92d9-7ab927b01e27"
      },
      "source": [
        "# give each letter a unique value\n",
        "chars = sorted(list({letter for word in sequences for letter in word}))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNa3pj-j07sf"
      },
      "source": [
        "# one hot encode x\n",
        "X = np.zeros((len(sequences), 5, len(chars)), dtype=np.uint8)\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_indices[char]] = 1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKDyjYrA2RF4"
      },
      "source": [
        "Y = np.array(labels)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "R663mkjNtswx",
        "outputId": "36387e50-6188-48d6-dba5-d5de8e289222"
      },
      "source": [
        "'''\n",
        "I was currious why this wouldn't work for me. I kept getting errors when I\n",
        "ran this. Does it only take one hot encodings as inputs?\n",
        "\n",
        "ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [100, 5]\n",
        "\n",
        "# encode the data based on the dictonary values\n",
        "endcoded = []\n",
        "for seq in sequences:\n",
        "  seqList = []\n",
        "  for letter in seq:\n",
        "    let_code = char_indices[letter]\n",
        "    seqList.append(let_code)\n",
        "  endcoded.append(seqList)\n",
        "X = np.array(endcoded)\n",
        "'''"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nI was currious why this wouldn't work for me. I kept getting errors when I\\nran this.\\n\\nValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [100, 5]\\n\\n# encode the data based on the dictonary values\\nendcoded = []\\nfor seq in sequences:\\n  seqList = []\\n  for letter in seq:\\n    let_code = char_indices[letter]\\n    seqList.append(let_code)\\n  endcoded.append(seqList)\\nX = np.array(endcoded)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSLXwJvJszDu"
      },
      "source": [
        "seq_rnn = Sequential()\n",
        "seq_rnn.add(tfkl.LSTM(50, input_shape=(5,26)))\n",
        "seq_rnn.add(tfkl.Dense(1,activation=\"sigmoid\"))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etdJm_KnzKy-"
      },
      "source": [
        "seq_rnn.compile(loss='binary_crossentropy', optimizer=tfk.optimizers.RMSprop(lr=0.01))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhjtD10lzjb3",
        "outputId": "87b5c428-ddd1-4db0-95fa-436b0dcf0fab"
      },
      "source": [
        "seq_rnn.fit(X,Y, epochs=20, batch_size=100)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1146\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.4382e-06\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.2718e-08\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 8.1950e-09\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 5.3324e-09\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.5072e-09\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.1212e-09\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.9320e-09\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.7220e-09\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.6976e-09\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.6263e-09\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.5714e-09\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.5193e-09\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.4884e-09\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.4194e-09\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.4294e-09\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.4056e-09\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.3781e-09\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.3848e-09\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb4879b4f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxliEcVa2LZa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}